/**
 * Real performance comparison test
 * Demonstrates actual speed improvements with realistic content
 */

import { extractEntitiesWithSlidingWindow, enhanceBlocksWithEntityContext, enhanceBlocksWithCaching } from '../../src/context.js';
import fs from 'fs';
import path from 'path';

// Mock AI that simulates realistic processing times
class RealisticMockAI {
  constructor(name, baseDelay = 100) {
    this.name = name;
    this.baseDelay = baseDelay;
    this.callCount = 0;
    this.totalTime = 0;
    this.cache = new Map();
  }

  async mockCall(prompt, schema, aiConfig) {
    this.callCount++;
    const start = Date.now();
    
    // Simulate cache behavior - check if we've seen this prefix before
    const promptPrefix = prompt.substring(0, 1000);
    const isCacheHit = this.cache.has(promptPrefix);
    
    if (isCacheHit) {
      // Cache hit - much faster processing
      await this.delay(this.baseDelay * 0.2);
    } else {
      // Cache miss - full processing time
      await this.delay(this.baseDelay + (prompt.length / 100));
      this.cache.set(promptPrefix, true);
    }
    
    const duration = Date.now() - start;
    this.totalTime += duration;
    
    console.log(`${this.name}: Call ${this.callCount}, ${duration}ms, ${isCacheHit ? 'CACHE HIT' : 'CACHE MISS'}`);
    
    // Return mock response
    if (prompt.includes('Extract all entities')) {
      return this.mockEntityResponse();
    } else {
      return this.mockEnhancementResponse(prompt);
    }
  }
  
  async delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
  
  mockEntityResponse() {
    return {
      people: [{ name: 'Chad Jones', roles: ['author'], context: 'Creator of Ocean' }],
      places: [{ name: 'India', type: 'country', context: 'Programming location' }],
      organizations: [{ name: 'US Publishing Trust', type: 'organization', context: 'Publishing plans' }],
      dates: [],
      events: [],
      subjects: ['Ocean search', 'BahÃ¡\'Ã­ literature'],
      relationships: []
    };
  }
  
  mockEnhancementResponse(prompt) {
    const originalMatch = prompt.match(/Original text: (\".*?\")/);
    let originalText = 'Enhanced text';
    
    if (originalMatch) {
      try {
        originalText = JSON.parse(originalMatch[1]);
      } catch (e) {
        // Use fallback
      }
    }
    
    // Apply realistic enhancements
    const enhanced = originalText
      .replace(/\\bI\\b/g, 'I (Chad Jones)')
      .replace(/\\bOcean\\b/g, 'Ocean (BahÃ¡\'Ã­ literature search software)')
      .replace(/\\bUS\\b/g, 'United States');
    
    return {
      contexted_markdown: enhanced,
      context_summary: 'Applied disambiguation rules'
    };
  }
  
  getStats() {
    return {
      name: this.name,
      calls: this.callCount,
      totalTime: this.totalTime,
      avgTime: this.callCount > 0 ? Math.round(this.totalTime / this.callCount) : 0,
      cacheHits: Array.from(this.cache.keys()).length
    };
  }
}

// Realistic article content (longer blocks)
const realisticBlocks = [
  { text: 'The story of Ocean search begins with a simple desire to bridge the gap between traditional BahÃ¡\'Ã­ literature and the burgeoning digital world. My journey, as the creator of this revolutionary search tool, began with youth service at the BahÃ¡\'Ã­ World Center in Haifa, Israel, where we learned to use the Unix Grep tool to search the core BahÃ¡\'Ã­ library.' },
  { text: 'This was a daily exercise and it created a longing to have basic search tools for ongoing study. A few years later, a personal turn of events led me to join my brother in India. It was here, amidst a different culture and environment, that the seeds for Ocean were sown.' },
  { text: 'I had already purchased an expensive scanner â€“ a significant investment at the time â€“ to start digitizing BahÃ¡\'Ã­ books. This was not just a task but a labor of love, driven by a commitment to digitize and share the rich heritage of BahÃ¡\'Ã­ literature.' },
  { text: 'While visiting the USA, I had enlightening conversations with the head of the US Publishing Trust. At the time, they had plans to sell electronic versions of each book, but the emerging popularity of CDs suggested to me a different opportunity.' },
  { text: 'While in India and China, and then India again, I immersed myself in learning Object Pascal through Delphi, an incredible tool for creating Windows applications. This was a time of growth and learning, driven by the goal of making BahÃ¡\'Ã­ texts more accessible.' },
  { text: 'One key realization during this journey was the fragility of applications with external dependencies â€“ something we used to refer to as "DLL Hell". Striving for a self-contained application, robust and reliable, became a guiding principle.' },
  { text: 'However, incorporating an inverted index or a database within a desired footprint was challenging. I had to find a way to make raw, \'grep-like\' searches fast and efficient.' },
  { text: 'This challenge led me to lurk in assembly-language forums, a community of optimization experts who were instrumental in developing Ocean\'s hand-tuned assembler version of the Boyer-Moore search algorithm.' },
  { text: 'With a bit of memory-mapping magic, Ocean began to perform like a database. Of course, this required some text manipulation â€“ removing diacritics from names in the Dawn-Breakers, for instance.' },
  { text: 'When I approached Mr. Shah with the complete version of Ocean, aware of its potential controversy, his encouragement was a beacon: "If nobody is complaining, then you\'re not doing anything worthwhile. Go for it!"' }
];

const metadata = {
  title: 'The Ocean Adventure: Making Ocean Search',
  url: 'https://bahai-education.org/the-ocean-adventure',
  description: 'Explore the birth of Ocean 1.0, a digital odyssey transforming Baha\'i literature.'
};

async function runPerformanceComparison() {
  console.log('ðŸš€ Real Performance Comparison: Traditional vs Cache-Optimized\\n');
  console.log(`Testing with ${realisticBlocks.length} content blocks\\n`);
  
  // Traditional approach
  console.log('ðŸ“Š Traditional Approach (No Caching)');
  console.log('=' * 40);
  
  const traditionalAI = new RealisticMockAI('Traditional', 150);
  const traditionalStart = Date.now();
  
  // Extract entities first
  const entityGraph = await extractEntitiesWithSlidingWindow(
    realisticBlocks.slice(0, 3),
    metadata,
    { provider: 'mock' },
    traditionalAI.mockCall.bind(traditionalAI)
  );
  
  // Enhance blocks individually
  const traditionalResult = await enhanceBlocksWithEntityContext(
    realisticBlocks,
    entityGraph,
    { provider: 'mock' },
    traditionalAI.mockCall.bind(traditionalAI)
  );
  
  const traditionalDuration = Date.now() - traditionalStart;
  const traditionalStats = traditionalAI.getStats();
  
  console.log(`\\nâœ… Traditional completed: ${traditionalDuration}ms`);
  console.log(`   AI calls: ${traditionalStats.calls}`);
  console.log(`   Avg call time: ${traditionalStats.avgTime}ms\\n`);
  
  // Cache-optimized approach
  console.log('âš¡ Cache-Optimized Approach');
  console.log('=' * 40);
  
  const cachedAI = new RealisticMockAI('Cache-Opt', 150);
  const cachedStart = Date.now();
  
  // Extract entities (same as before)
  const cachedEntityGraph = await extractEntitiesWithSlidingWindow(
    realisticBlocks.slice(0, 3),
    metadata,
    { provider: 'mock' },
    cachedAI.mockCall.bind(cachedAI)
  );
  
  // Enhanced blocks with caching
  const cachedResult = await enhanceBlocksWithCaching(
    realisticBlocks,
    cachedEntityGraph,
    metadata,
    { provider: 'mock' },
    cachedAI.mockCall.bind(cachedAI)
  );
  
  const cachedStats = cachedAI.getStats();
  
  console.log(`\\nâœ… Cache-optimized completed: ${cachedResult.duration}ms`);
  console.log(`   AI calls: ${cachedStats.calls}`);
  console.log(`   Avg call time: ${cachedStats.avgTime}ms\\n`);
  
  // Performance comparison
  console.log('ðŸ“ˆ PERFORMANCE COMPARISON');
  console.log('=' * 50);
  console.log(`Traditional:     ${traditionalDuration}ms (${traditionalStats.calls} calls)`);
  console.log(`Cache-optimized: ${cachedResult.duration}ms (${cachedStats.calls} calls)`);
  console.log(`Speed improvement: ${(traditionalDuration / cachedResult.duration).toFixed(1)}x faster`);
  console.log(`Call reduction: ${Math.round((1 - cachedStats.calls / traditionalStats.calls) * 100)}%`);
  console.log(`Efficiency gain: ${Math.round(((traditionalDuration - cachedResult.duration) / traditionalDuration) * 100)}%\\n`);
  
  // Save results
  const perfResults = {
    testConfig: {
      blockCount: realisticBlocks.length,
      baseDelay: '150ms',
      testDate: new Date().toISOString()
    },
    traditional: {
      duration: traditionalDuration,
      calls: traditionalStats.calls,
      avgCallTime: traditionalStats.avgTime
    },
    cacheOptimized: {
      duration: cachedResult.duration,
      calls: cachedStats.calls,
      avgCallTime: cachedStats.avgTime
    },
    improvements: {
      speedMultiplier: Math.round((traditionalDuration / cachedResult.duration) * 10) / 10,
      callReduction: Math.round((1 - cachedStats.calls / traditionalStats.calls) * 100),
      efficiencyGain: Math.round(((traditionalDuration - cachedResult.duration) / traditionalDuration) * 100)
    }
  };
  
  const perfFile = path.join(process.cwd(), 'tests/debug/cache-output/performance_results.json');
  fs.writeFileSync(perfFile, JSON.stringify(perfResults, null, 2));
  
  console.log(`ðŸ’¾ Performance results saved to ${perfFile}`);
  console.log('\\nðŸŽ‰ Performance comparison completed!');
}

// Run the test
runPerformanceComparison().catch(console.error);